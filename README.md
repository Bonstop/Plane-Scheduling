# 如何利用强化学习解决调度问题？
## 一、约束条件设置
![Image text](https://raw.githubusercontent.com/Bonstop/Plane-Scheduling/master/picture/约束条件.png)
## 二、强化学习的一点感想
在一开始，我试图将整个顺序进行排序，但是发现有两个问题：其一，单步调节永远没有结果，谁也不知道最后的情况是什么样子；其二，单步调节的选择很麻烦，当时动作设计也有问题，导致很多的飞机无法进行调节，最后卡死，尝试过随机数据，和响应比调度也无法解决。针对以上的问题，尝试重新思考，目前效果很好。（4架飞机，随后补充更多的飞机）
我发现一个强化学习很巧妙的方法，那就是想想正常人如何解决这个问题，然后用程序表达出来就完事了。就好比是说我们写数学题，“这个数学题我做过，很熟”，这就是强化学习想要表达的。只要机器的Q表状态见的多了，根据奖赏自然而然就能做出一个动作。假设我们人去排飞机，那就是随便拿一个，拿N次，然后看看结果。唯一可以记录的就是眼前的各种状态，而动作那就是拿各个飞机了。只要拍完了，比上次好，那就给一块糖。这不是就很容易了嘛？

## 三、强化学习状态设置
**状态值：** 根据我前面的感想，很容易就发现可以将眼前的N个飞机设置为状态。一个飞机为两个状态（分别是选中拿走状态和未选中拿走状态），一共 N 个飞机，就有 2^N 个状态。  <br/> **动作：** 拿各个飞机就是动作。一共 N 个飞机，所以有 N 个动作。 <br/> **奖励值：** 因为 Agent 不同于人，比较“笨”，还得告诉它不要拿走A飞机排序之后又去飞机堆里找A飞机（骑着毛驴找毛驴），所以在这个时候就给予奖励，一共N个飞机，恰好N步排好就给你一个奖励；如果能减小间隔时间的话就更好了，再给你个“额外奖励”。

## 四、数据分析
![Image text](https://raw.githubusercontent.com/Bonstop/Plane-Scheduling/master/picture/迭代100次效果%EF%BC%884架飞机%EF%BC%89.jpg)
